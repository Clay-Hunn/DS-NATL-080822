{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /Users/julianward/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /Users/julianward/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in /Users/julianward/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/julianward/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in /Users/julianward/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Splits\n",
    "\n",
    "### The Problem\n",
    "\n",
    "When building a predictive model we can run into a problem of overfitting. \n",
    "\n",
    "**OVERFITTING WILL BE A MAJOR TOPIC WE WILL DEAL WITH FOR AS LONG AS WE MAKE PREDICTIVE MODELS**\n",
    "\n",
    "Overfitting is a model that does *too well* on the data we've given in, so much so that it makes the model *worse* at looking at new data.\n",
    "\n",
    "Take this data for example:\n",
    "\n",
    "![Clearly linear scatterplot](./justdot.png)\n",
    "\n",
    "It's our data is pretty clearly linear, a linear model wouldn't prefectly predict every point, but it would be pretty good.\n",
    "\n",
    "![Simple linear model](./propermodel.png)\n",
    "\n",
    "Buuuuuuuut I could totally write an algorithm or funtion that perfectly hits every point here.\n",
    "\n",
    "!['Better' model](./overfitmodel.png)\n",
    "\n",
    "\n",
    "This second model will perform better on any metrics we feed into it... FOR THESE SPECIFIC DATA POINTS. \n",
    "\n",
    "But, we want models that make predictions. That's 99% of the point of data science. \n",
    "\n",
    "If we tried to feed our models new information (e.g. use the model in the real world) the 'worse' model will perform much better.\n",
    "\n",
    "![New data comparison](./withnewdata.png)\n",
    "\n",
    "\n",
    "\n",
    "So how do we know if our model is overfit? We can't magically create new data, but we can HIDE data from the model, only to reveal it later. This is the train-test split. We train the models on one set of data, we verify the model's performance on the test data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting an example dataset\n",
    "\n",
    "Let's grab a dataset and see how this works. I'm just grabbing the diabetes dataset from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.00</td>\n",
       "      <td>157.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.00</td>\n",
       "      <td>183.0</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.00</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.00</td>\n",
       "      <td>198.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>112.00</td>\n",
       "      <td>185.0</td>\n",
       "      <td>113.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.9836</td>\n",
       "      <td>93.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>75.00</td>\n",
       "      <td>225.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.4427</td>\n",
       "      <td>102.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>99.67</td>\n",
       "      <td>162.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.1271</td>\n",
       "      <td>95.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>201.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.1299</td>\n",
       "      <td>85.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>71.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>133.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5951</td>\n",
       "      <td>92.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   bmi      bp     s1     s2    s3    s4      s5     s6  target\n",
       "0    59.0  2.0  32.1  101.00  157.0   93.2  38.0  4.00  4.8598   87.0   151.0\n",
       "1    48.0  1.0  21.6   87.00  183.0  103.2  70.0  3.00  3.8918   69.0    75.0\n",
       "2    72.0  2.0  30.5   93.00  156.0   93.6  41.0  4.00  4.6728   85.0   141.0\n",
       "3    24.0  1.0  25.3   84.00  198.0  131.4  40.0  5.00  4.8903   89.0   206.0\n",
       "4    50.0  1.0  23.0  101.00  192.0  125.4  52.0  4.00  4.2905   80.0   135.0\n",
       "..    ...  ...   ...     ...    ...    ...   ...   ...     ...    ...     ...\n",
       "437  60.0  2.0  28.2  112.00  185.0  113.8  42.0  4.00  4.9836   93.0   178.0\n",
       "438  47.0  2.0  24.9   75.00  225.0  166.0  42.0  5.00  4.4427  102.0   104.0\n",
       "439  60.0  2.0  24.9   99.67  162.0  106.6  43.0  3.77  4.1271   95.0   132.0\n",
       "440  36.0  1.0  30.0   95.00  201.0  125.2  42.0  4.79  5.1299   85.0   220.0\n",
       "441  36.0  1.0  19.6   71.00  250.0  133.2  97.0  3.00  4.5951   92.0    57.0\n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first we load the dataset. load_diabetes has an option to load directly as a pandas df\n",
    "\n",
    "diabetes_df = datasets.load_diabetes(as_frame=True, scaled = False).frame\n",
    "# choosing 'as_frame = True' makes the dataset a pandas DF, setting scaled = False\n",
    "# means that we get the raw data, and I'll talk about why I did that later.\n",
    "# NOTE! That's not an option in the version of sklearn y'all have.\n",
    "\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the FIRST thing we want to do is the train-test-split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._split.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the part of the lecture where I verbally explain all the options for train_test_split\n",
    "train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The options to input into train_test_split:\n",
    "\n",
    "##### arrays\n",
    "First, we MUST pass in arrays. They must be \"sequence of indexables with same length / shape\" That is, the same number of rows, and those rows must match up. So row 1 in one array needs to map to row 1 in the second array.  In this case, our X variables or predictors, and our Y variables or target. \n",
    "\n",
    "##### test_size\n",
    "Next, we can choose the test_size. We can set this manually, or use the default. The default is .25, or 25% of the data. If we pass an int it will set the size of the test size to that int, if we pass a value between 1 and 0 it makes the test dataset a corresponding % of the overall dataset. The default here is fine for most use cases.\n",
    "\n",
    "##### train_size\n",
    "Or we can set the training size instead of the test size. But usually we want to use all the data we don't put into the test set, so by default we leave this untouched.\n",
    "\n",
    "##### random_state\n",
    "So, we want our tts to be randomized, otherwise we'll bias the samples and blahblahblah. Buuuuut we want to be able to open and close the notebook and have our results be repeatable. So here we usually want to pass in some arbitary random seed, so that each time the TTS is run *on the same dataset* you end up with the same random result. best practice is to pick a number and stick with it. Because programmers are nerds, 42 is a fairly widely used arbitrary seed. I do 14 because that's my lucky number. You can do whatever, it just forces the split to be the same each time you run it.\n",
    "\n",
    "##### shuffle \n",
    "Shuffle is a boolean option that defaults to true. Basically it makes sure that you're actually grabbing data points randomly, which we almost always want to do. \n",
    "\n",
    "##### stratify\n",
    "You can pass in an array to have the split try to ensure that it balances the split based on the contents of that array. Usually we don't do this, and if we do, usually we stratify by the target. \n",
    "\n",
    "For an example of when we might use this, if we have a classification dataset that has some very rare values in the target, we might want to force the t-t-s to try to make sure there's an equal proportion of each possible target in the train and the test. This is a problem that goes away with bigger datasets thanks to the Law of Large Numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our train_test_split\n",
    "\n",
    "##### arrays\n",
    "\n",
    "Our arrays will be the predictors on one hand and the target on the other. In this case, we'll use diabetes_df.drop('target', axis = 0) and diabetes_df.target\n",
    "\n",
    "##### test_size\n",
    "\n",
    "We can leave this as default.\n",
    "\n",
    "##### train_size\n",
    "\n",
    "We can leave this as default.\n",
    "\n",
    "##### random_state\n",
    "\n",
    "I'm going to set this at 14 just because I can.\n",
    "\n",
    "##### shuffle\n",
    "\n",
    "We can leave this as default.\n",
    "\n",
    "##### stratify\n",
    "\n",
    "We can leave this as default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      age  sex   bmi     bp     s1     s2    s3    s4      s5     s6\n",
       " 16   47.0  1.0  30.3  109.0  207.0  100.2  70.0  3.00  5.2149   98.0\n",
       " 408  66.0  1.0  21.7  126.0  212.0  127.8  45.0  4.71  5.2781  101.0\n",
       " 432  51.0  1.0  31.5   93.0  231.0  144.0  49.0  4.70  5.2523  117.0\n",
       " 316  53.0  2.0  27.7   95.0  190.0  101.8  41.0  5.00  5.4638  101.0\n",
       " 3    24.0  1.0  25.3   84.0  198.0  131.4  40.0  5.00  4.8903   89.0\n",
       " ..    ...  ...   ...    ...    ...    ...   ...   ...     ...    ...\n",
       " 106  22.0  1.0  19.3   82.0  156.0   93.2  52.0  3.00  3.9890   71.0\n",
       " 270  50.0  2.0  29.2  119.0  162.0   85.2  54.0  3.00  4.7362   95.0\n",
       " 348  57.0  1.0  24.5   93.0  186.0   96.6  71.0  3.00  4.5218   91.0\n",
       " 435  45.0  1.0  24.2   83.0  177.0  118.4  45.0  4.00  4.2195   82.0\n",
       " 102  23.0  1.0  29.0   90.0  216.0  131.4  65.0  3.00  4.5850   91.0\n",
       " \n",
       " [331 rows x 10 columns],\n",
       "       age  sex   bmi      bp     s1     s2    s3    s4      s5     s6\n",
       " 287  61.0  1.0  25.8   90.00  280.0  195.4  55.0  5.00  4.9972   90.0\n",
       " 211  74.0  1.0  29.8  101.00  171.0  104.8  50.0  3.00  4.3944   86.0\n",
       " 72   66.0  2.0  26.0   91.00  264.0  146.6  65.0  4.00  5.5683   87.0\n",
       " 321  75.0  1.0  31.2  117.67  229.0  138.8  29.0  7.90  5.7236  106.0\n",
       " 73   52.0  2.0  24.5   94.00  217.0  149.4  48.0  5.00  4.5850   89.0\n",
       " ..    ...  ...   ...     ...    ...    ...   ...   ...     ...    ...\n",
       " 45   56.0  2.0  23.1  104.00  181.0  116.4  47.0  4.00  4.4773   79.0\n",
       " 153  60.0  2.0  22.3  113.00  186.0  125.8  46.0  4.00  4.2627   94.0\n",
       " 239  55.0  1.0  28.2   91.00  250.0  140.2  67.0  4.00  5.3660  103.0\n",
       " 380  53.0  1.0  28.8  111.67  145.0   87.2  46.0  3.15  4.0775   85.0\n",
       " 278  67.0  2.0  23.0   70.00  184.0  128.0  35.0  5.00  4.6540   99.0\n",
       " \n",
       " [111 rows x 10 columns],\n",
       " 16     166.0\n",
       " 408    189.0\n",
       " 432    173.0\n",
       " 316    220.0\n",
       " 3      206.0\n",
       "        ...  \n",
       " 106    134.0\n",
       " 270    202.0\n",
       " 348    148.0\n",
       " 435     64.0\n",
       " 102    302.0\n",
       " Name: target, Length: 331, dtype: float64,\n",
       " 287    219.0\n",
       " 211     70.0\n",
       " 72     202.0\n",
       " 321    230.0\n",
       " 73     111.0\n",
       "        ...  \n",
       " 45      53.0\n",
       " 153     71.0\n",
       " 239    262.0\n",
       " 380     52.0\n",
       " 278    102.0\n",
       " Name: target, Length: 111, dtype: float64]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(diabetes_df.drop('target', axis = 1), diabetes_df.target, random_state = 42)\n",
    "\n",
    "# This output is strange. train_test_split returns four arrays, so we need to set it to four different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes_df.drop('target', axis = 1), diabetes_df.target, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>90.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>195.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9972</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>101.00</td>\n",
       "      <td>171.0</td>\n",
       "      <td>104.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3944</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>146.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5683</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>117.67</td>\n",
       "      <td>229.0</td>\n",
       "      <td>138.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.7236</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>94.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>149.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   bmi      bp     s1     s2    s3   s4      s5     s6\n",
       "287  61.0  1.0  25.8   90.00  280.0  195.4  55.0  5.0  4.9972   90.0\n",
       "211  74.0  1.0  29.8  101.00  171.0  104.8  50.0  3.0  4.3944   86.0\n",
       "72   66.0  2.0  26.0   91.00  264.0  146.6  65.0  4.0  5.5683   87.0\n",
       "321  75.0  1.0  31.2  117.67  229.0  138.8  29.0  7.9  5.7236  106.0\n",
       "73   52.0  2.0  24.5   94.00  217.0  149.4  48.0  5.0  4.5850   89.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16     166.0\n",
       "408    189.0\n",
       "432    173.0\n",
       "316    220.0\n",
       "3      206.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287    219.0\n",
       "211     70.0\n",
       "72     202.0\n",
       "321    230.0\n",
       "73     111.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the way the indices line up. This is why indices are important!\n",
    "\n",
    "Note also how the indices have been randomized. \n",
    "\n",
    "Since our target was just a single column, y_train and y_test came out as a series while X_train and X_test came out as full dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data leaking\n",
    "\n",
    "This leads to problems of data leakage, or, the possibility of, unless we're careful, information from the test set 'leaking' its way into our training data. This can happen a lot of ways, and we need to keep an eye out for it. \n",
    "\n",
    "For instance, check out [this paper](https://reproducible.cs.princeton.edu/), which is just some data scientists calling out other, seasoned and experienced academic data scientists for messing up data leakage. Note, that, kinda like the example we gave above, fixing the data leaks often led to the fancy shmancy algos performing only about as well as the simpler models.\n",
    "\n",
    "**We now need to take X_test and Y_test and hide them away. Lock the door, hide the key**\n",
    "\n",
    "We now want to do our pre-processing steps on X_train and y_train, and then be ready to, *once we've already built the model*, be able to reapply those steps to the test data.\n",
    "\n",
    "So what's some preprocessing we need to do?\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".(image3)[Dora the Explorer]\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "That's right! We might want to scale this data, and we for sure need to do some one hot encoding for our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are, as Jelly would say it 'in-STAUNCH-ee-a-ting' our ohe and scaler\n",
    "ohe1 = OneHotEncoder(sparse = False, drop = 'first', handle_unknown = 'ignore')\n",
    "scaler1 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>30.3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.2149</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>66.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>21.7</td>\n",
       "      <td>126.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>127.8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.2781</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>51.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>31.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.2523</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>27.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>101.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.4638</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>19.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.9890</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>29.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.7362</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>57.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>24.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5218</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>24.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2195</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>29.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   sex   bmi     bp     s1     s2    s3    s4      s5     s6\n",
       "16   47.0  Jock  30.3  109.0  207.0  100.2  70.0  3.00  5.2149   98.0\n",
       "408  66.0  Jock  21.7  126.0  212.0  127.8  45.0  4.71  5.2781  101.0\n",
       "432  51.0  Jock  31.5   93.0  231.0  144.0  49.0  4.70  5.2523  117.0\n",
       "316  53.0  Nerd  27.7   95.0  190.0  101.8  41.0  5.00  5.4638  101.0\n",
       "3    24.0  Jock  25.3   84.0  198.0  131.4  40.0  5.00  4.8903   89.0\n",
       "..    ...   ...   ...    ...    ...    ...   ...   ...     ...    ...\n",
       "106  22.0  Jock  19.3   82.0  156.0   93.2  52.0  3.00  3.9890   71.0\n",
       "270  50.0  Nerd  29.2  119.0  162.0   85.2  54.0  3.00  4.7362   95.0\n",
       "348  57.0  Jock  24.5   93.0  186.0   96.6  71.0  3.00  4.5218   91.0\n",
       "435  45.0  Jock  24.2   83.0  177.0  118.4  45.0  4.00  4.2195   82.0\n",
       "102  23.0  Jock  29.0   90.0  216.0  131.4  65.0  3.00  4.5850   91.0\n",
       "\n",
       "[331 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since for the life of me I can't track down what sex is supposed to map to, \n",
    "# I'm going with an arbitrary replacement.\n",
    "X_train.sex.replace({1: 'Jock', 2:'Nerd'}, inplace = True)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this fits the encoder on the column we need\n",
    "sex_ohe = ohe1.fit(X_train[['sex']])\n",
    "\n",
    "# this creates a new object by putting the encoder to the column,\n",
    "# then creates a DataFrame from that object, the label for the undropped column, \n",
    "# and the index from the training dataset\n",
    "\n",
    "sex_encoded = pd.DataFrame(sex_ohe.transform(X_train[['sex']]), columns=['Nerd'], index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nerd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nerd\n",
       "16    0.0\n",
       "408   0.0\n",
       "432   0.0\n",
       "316   1.0\n",
       "3     0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to add a column to our X_train dataset. \n",
    "\n",
    "X_train_encoded = pd.concat([X_train, sex_encoded['Nerd']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Nerd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>30.3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.2149</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>66.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>21.7</td>\n",
       "      <td>126.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>127.8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.2781</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>51.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>31.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.2523</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>27.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>101.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.4638</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>19.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.9890</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>29.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.7362</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>57.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>24.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5218</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>24.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2195</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>29.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   sex   bmi     bp     s1     s2    s3    s4      s5     s6  Nerd\n",
       "16   47.0  Jock  30.3  109.0  207.0  100.2  70.0  3.00  5.2149   98.0   0.0\n",
       "408  66.0  Jock  21.7  126.0  212.0  127.8  45.0  4.71  5.2781  101.0   0.0\n",
       "432  51.0  Jock  31.5   93.0  231.0  144.0  49.0  4.70  5.2523  117.0   0.0\n",
       "316  53.0  Nerd  27.7   95.0  190.0  101.8  41.0  5.00  5.4638  101.0   1.0\n",
       "3    24.0  Jock  25.3   84.0  198.0  131.4  40.0  5.00  4.8903   89.0   0.0\n",
       "..    ...   ...   ...    ...    ...    ...   ...   ...     ...    ...   ...\n",
       "106  22.0  Jock  19.3   82.0  156.0   93.2  52.0  3.00  3.9890   71.0   0.0\n",
       "270  50.0  Nerd  29.2  119.0  162.0   85.2  54.0  3.00  4.7362   95.0   1.0\n",
       "348  57.0  Jock  24.5   93.0  186.0   96.6  71.0  3.00  4.5218   91.0   0.0\n",
       "435  45.0  Jock  24.2   83.0  177.0  118.4  45.0  4.00  4.2195   82.0   0.0\n",
       "102  23.0  Jock  29.0   90.0  216.0  131.4  65.0  3.00  4.5850   91.0   0.0\n",
       "\n",
       "[331 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm calling this just to spot check that the 'Nerd' column = 1 when sex = 'Nerd' and\n",
    "# Nerd = 0 when sex = 'Jock'\n",
    "# I could do this more rigourously but this works for now.\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.drop(['sex'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since I know I'll need to repeat this later, I'll make a function for everything EXCEPT the fit step.\n",
    "\n",
    "def ohe_for_diabetes(data_df, fit_encoder):\n",
    "    data_df.sex.replace({1: 'Jock', 2:'Nerd'}, inplace = True)\n",
    "    data_sex_encoded = pd.DataFrame(fit_encoder.transform(data_df[['sex']]), columns=['Nerd'], index = data_df.index)\n",
    "    data_df_encoded = pd.concat([data_df, data_sex_encoded['Nerd']], axis = 1)\n",
    "    display(data_df_encoded)\n",
    "    ### I am including this so we can sanity check that \n",
    "    data_df_encoded.drop(['sex'], axis = 1, inplace= True)\n",
    "    return data_df_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Nerd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>25.8</td>\n",
       "      <td>90.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>195.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.9972</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>74.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>29.8</td>\n",
       "      <td>101.00</td>\n",
       "      <td>171.0</td>\n",
       "      <td>104.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.3944</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>66.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>26.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>146.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.5683</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>75.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>31.2</td>\n",
       "      <td>117.67</td>\n",
       "      <td>229.0</td>\n",
       "      <td>138.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>5.7236</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>24.5</td>\n",
       "      <td>94.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>149.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>23.1</td>\n",
       "      <td>104.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>116.4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.4773</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>22.3</td>\n",
       "      <td>113.00</td>\n",
       "      <td>186.0</td>\n",
       "      <td>125.8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2627</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>28.2</td>\n",
       "      <td>91.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>140.2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.3660</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Jock</td>\n",
       "      <td>28.8</td>\n",
       "      <td>111.67</td>\n",
       "      <td>145.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>4.0775</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>67.0</td>\n",
       "      <td>Nerd</td>\n",
       "      <td>23.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>184.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.6540</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   sex   bmi      bp     s1     s2    s3    s4      s5     s6  Nerd\n",
       "287  61.0  Jock  25.8   90.00  280.0  195.4  55.0  5.00  4.9972   90.0   0.0\n",
       "211  74.0  Jock  29.8  101.00  171.0  104.8  50.0  3.00  4.3944   86.0   0.0\n",
       "72   66.0  Nerd  26.0   91.00  264.0  146.6  65.0  4.00  5.5683   87.0   1.0\n",
       "321  75.0  Jock  31.2  117.67  229.0  138.8  29.0  7.90  5.7236  106.0   0.0\n",
       "73   52.0  Nerd  24.5   94.00  217.0  149.4  48.0  5.00  4.5850   89.0   1.0\n",
       "..    ...   ...   ...     ...    ...    ...   ...   ...     ...    ...   ...\n",
       "45   56.0  Nerd  23.1  104.00  181.0  116.4  47.0  4.00  4.4773   79.0   1.0\n",
       "153  60.0  Nerd  22.3  113.00  186.0  125.8  46.0  4.00  4.2627   94.0   1.0\n",
       "239  55.0  Jock  28.2   91.00  250.0  140.2  67.0  4.00  5.3660  103.0   0.0\n",
       "380  53.0  Jock  28.8  111.67  145.0   87.2  46.0  3.15  4.0775   85.0   0.0\n",
       "278  67.0  Nerd  23.0   70.00  184.0  128.0  35.0  5.00  4.6540   99.0   1.0\n",
       "\n",
       "[111 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Don't do this but I want to prove a point:\n",
    "\n",
    "X_test_encoded = ohe_for_diabetes(data_df = X_test, fit_encoder = sex_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, that was kind of a pain, but we're set up for categorical columns now. On to scaling!\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Nerd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>100.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.2149</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>66.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>126.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>127.8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.2781</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>51.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.2523</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>53.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>101.8</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.4638</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.9890</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>50.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.7362</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>57.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5218</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>45.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2195</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5850</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   bmi     bp     s1     s2    s3    s4      s5     s6  Nerd\n",
       "16   47.0  30.3  109.0  207.0  100.2  70.0  3.00  5.2149   98.0   0.0\n",
       "408  66.0  21.7  126.0  212.0  127.8  45.0  4.71  5.2781  101.0   0.0\n",
       "432  51.0  31.5   93.0  231.0  144.0  49.0  4.70  5.2523  117.0   0.0\n",
       "316  53.0  27.7   95.0  190.0  101.8  41.0  5.00  5.4638  101.0   1.0\n",
       "3    24.0  25.3   84.0  198.0  131.4  40.0  5.00  4.8903   89.0   0.0\n",
       "..    ...   ...    ...    ...    ...   ...   ...     ...    ...   ...\n",
       "106  22.0  19.3   82.0  156.0   93.2  52.0  3.00  3.9890   71.0   0.0\n",
       "270  50.0  29.2  119.0  162.0   85.2  54.0  3.00  4.7362   95.0   1.0\n",
       "348  57.0  24.5   93.0  186.0   96.6  71.0  3.00  4.5218   91.0   0.0\n",
       "435  45.0  24.2   83.0  177.0  118.4  45.0  4.00  4.2195   82.0   0.0\n",
       "102  23.0  29.0   90.0  216.0  131.4  65.0  3.00  4.5850   91.0   0.0\n",
       "\n",
       "[331 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to some preprocessing\n",
    "# I got lazy here, can you spot it? It won't effect the model but it's still bad practice\n",
    "\n",
    "scaler1.fit(X_train_encoded)\n",
    "X_train_scaled = pd.DataFrame(scaler1.transform(X_train_encoded), \n",
    "                              columns=X_train_encoded.columns,\n",
    "                              index = X_train_encoded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Nerd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.140760</td>\n",
       "      <td>0.847910</td>\n",
       "      <td>1.006118</td>\n",
       "      <td>0.499667</td>\n",
       "      <td>-0.495708</td>\n",
       "      <td>1.595610</td>\n",
       "      <td>-0.836153</td>\n",
       "      <td>1.053499</td>\n",
       "      <td>0.520279</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.347042</td>\n",
       "      <td>-1.118412</td>\n",
       "      <td>2.229852</td>\n",
       "      <td>0.642812</td>\n",
       "      <td>0.400279</td>\n",
       "      <td>-0.362375</td>\n",
       "      <td>0.471261</td>\n",
       "      <td>1.173589</td>\n",
       "      <td>0.782398</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.172461</td>\n",
       "      <td>1.122280</td>\n",
       "      <td>-0.145632</td>\n",
       "      <td>1.186763</td>\n",
       "      <td>0.926185</td>\n",
       "      <td>-0.049098</td>\n",
       "      <td>0.463615</td>\n",
       "      <td>1.124565</td>\n",
       "      <td>2.180368</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.329072</td>\n",
       "      <td>0.253440</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>-0.443767</td>\n",
       "      <td>-0.675653</td>\n",
       "      <td>0.692986</td>\n",
       "      <td>1.526449</td>\n",
       "      <td>0.782398</td>\n",
       "      <td>1.059148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.941785</td>\n",
       "      <td>-0.295300</td>\n",
       "      <td>-0.793492</td>\n",
       "      <td>0.242006</td>\n",
       "      <td>0.517147</td>\n",
       "      <td>-0.753972</td>\n",
       "      <td>0.692986</td>\n",
       "      <td>0.436706</td>\n",
       "      <td>-0.266079</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-2.098396</td>\n",
       "      <td>-1.667152</td>\n",
       "      <td>-0.937461</td>\n",
       "      <td>-0.960412</td>\n",
       "      <td>-0.722951</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>-0.836153</td>\n",
       "      <td>-1.275911</td>\n",
       "      <td>-1.838795</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.094156</td>\n",
       "      <td>0.596403</td>\n",
       "      <td>1.725961</td>\n",
       "      <td>-0.788638</td>\n",
       "      <td>-0.982657</td>\n",
       "      <td>0.342499</td>\n",
       "      <td>-0.836153</td>\n",
       "      <td>0.143891</td>\n",
       "      <td>0.258160</td>\n",
       "      <td>1.059148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.642294</td>\n",
       "      <td>-0.478214</td>\n",
       "      <td>-0.145632</td>\n",
       "      <td>-0.101542</td>\n",
       "      <td>-0.612576</td>\n",
       "      <td>1.673929</td>\n",
       "      <td>-0.836153</td>\n",
       "      <td>-0.263504</td>\n",
       "      <td>-0.091333</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-0.297371</td>\n",
       "      <td>-0.546807</td>\n",
       "      <td>-0.865476</td>\n",
       "      <td>-0.359203</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>-0.362375</td>\n",
       "      <td>-0.071583</td>\n",
       "      <td>-0.837924</td>\n",
       "      <td>-0.877691</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-2.020090</td>\n",
       "      <td>0.550675</td>\n",
       "      <td>-0.361586</td>\n",
       "      <td>0.757328</td>\n",
       "      <td>0.517147</td>\n",
       "      <td>1.204013</td>\n",
       "      <td>-0.836153</td>\n",
       "      <td>-0.143414</td>\n",
       "      <td>-0.091333</td>\n",
       "      <td>-0.944155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       bmi        bp        s1        s2        s3        s4  \\\n",
       "16  -0.140760  0.847910  1.006118  0.499667 -0.495708  1.595610 -0.836153   \n",
       "408  1.347042 -1.118412  2.229852  0.642812  0.400279 -0.362375  0.471261   \n",
       "432  0.172461  1.122280 -0.145632  1.186763  0.926185 -0.049098  0.463615   \n",
       "316  0.329072  0.253440 -0.001664  0.012974 -0.443767 -0.675653  0.692986   \n",
       "3   -1.941785 -0.295300 -0.793492  0.242006  0.517147 -0.753972  0.692986   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106 -2.098396 -1.667152 -0.937461 -0.960412 -0.722951  0.185861 -0.836153   \n",
       "270  0.094156  0.596403  1.725961 -0.788638 -0.982657  0.342499 -0.836153   \n",
       "348  0.642294 -0.478214 -0.145632 -0.101542 -0.612576  1.673929 -0.836153   \n",
       "435 -0.297371 -0.546807 -0.865476 -0.359203  0.095124 -0.362375 -0.071583   \n",
       "102 -2.020090  0.550675 -0.361586  0.757328  0.517147  1.204013 -0.836153   \n",
       "\n",
       "           s5        s6      Nerd  \n",
       "16   1.053499  0.520279 -0.944155  \n",
       "408  1.173589  0.782398 -0.944155  \n",
       "432  1.124565  2.180368 -0.944155  \n",
       "316  1.526449  0.782398  1.059148  \n",
       "3    0.436706 -0.266079 -0.944155  \n",
       "..        ...       ...       ...  \n",
       "106 -1.275911 -1.838795 -0.944155  \n",
       "270  0.143891  0.258160  1.059148  \n",
       "348 -0.263504 -0.091333 -0.944155  \n",
       "435 -0.837924 -0.877691 -0.944155  \n",
       "102 -0.143414 -0.091333 -0.944155  \n",
       "\n",
       "[331 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler1.transform(X_test_encoded), \n",
    "                              columns=X_test_encoded.columns,\n",
    "                              index = X_test_encoded.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4849058889476756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='target'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "sns.scatterplot(x = y_pred, y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519034189167905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model.score(X_train_scaled, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52899012, 0.39018414, 0.49129656, 0.61104149, 0.2252414 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
